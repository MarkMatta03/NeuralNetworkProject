# Neural Network From Scratch â€” Part 1

This project implements a complete neural network **from scratch using NumPy only**, without using deep learning frameworks such as TensorFlow or PyTorch.  
This work fulfills **Part 1** of the semester project requirements.

---

## ğŸ¯ Objectives of Part 1

âœ” Build a modular neural network library  
âœ” Implement:
- Dense (Fully Connected) Layers  
- Activation Functions (Sigmoid, Tanh)  
- Mean Squared Error (MSE) Loss  
- Stochastic Gradient Descent (SGD) optimizer  

âœ” Train the model to learn the XOR logic function  
âœ” Perform Gradient Checking to verify correctness of backpropagation  
âœ” Present training results in a Jupyter Notebook

---

## ğŸ§  XOR Problem Training

The XOR truth table:

| Input | Output |
|------|--------|
| (0,0) | 0 |
| (0,1) | 1 |
| (1,0) | 1 |
| (1,1) | 0 |

The neural network architecture used:

Input(2) â†’ Dense(4) + Tanh â†’ Dense(1) + Sigmoid

Training Configuration:

- Loss function: **MSE**
- Optimization: **SGD**
- Epochs: 50,000

### âœ” Final XOR Predictions

[[0.01]
[0.98]
[0.98]
[0.02]]

â¡ The model successfully learns XOR ğŸ‰

---

## ğŸ“ˆ Training Loss Curve

The loss smoothly approaches ~0 during training.

ğŸ“ Included inside:
notebooks/project_demo.ipynb
---

## ğŸ§ª Gradient Checking

To ensure the correctness of backpropagation:

- Numerical gradients were calculated using finite difference
- Compared with analytical gradients from backward pass

Result:
Maximum difference â‰ˆ 1e-5
âœ” Confirms backpropagation implementation is correct

---

## ğŸ“ Project Structure

NeuralNetworkProject/
â”‚
â”œâ”€ lib/
â”‚ â”œâ”€ layers.py # Dense layer + SGD update
â”‚ â”œâ”€ activations.py # Sigmoid & Tanh
â”‚ â”œâ”€ losses.py # MSE + gradient
â”‚ â”œâ”€ network.py # Sequential model container
â”‚
â”œâ”€ notebooks/
â”‚ â””â”€ project_demo.ipynb # Part 1 report & results
â”‚
â”œâ”€ xor_mse_test.py # Quick test script for XOR
â””â”€ README.md
---

## â–¶ï¸ How to Run

Open Terminal in project root:

```bash
python -m xor_mse_test
Or open the notebook:
notebooks/project_demo.ipynb
